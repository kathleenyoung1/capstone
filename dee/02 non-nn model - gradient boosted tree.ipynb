{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "appreciated-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alone-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('summary_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unknown-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "valuable-anderson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_role</th>\n",
       "      <th>word_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>gs_score</th>\n",
       "      <th>pitch_log_diff_variance</th>\n",
       "      <th>pitch_log_mean</th>\n",
       "      <th>pitch_log_stdev</th>\n",
       "      <th>pitch_log_2pct</th>\n",
       "      <th>pitch_log_25pct</th>\n",
       "      <th>pitch_log_50pct</th>\n",
       "      <th>pitch_log_75pct</th>\n",
       "      <th>pitch_log_98pct</th>\n",
       "      <th>onset_count</th>\n",
       "      <th>onset_str_mean</th>\n",
       "      <th>onset_str_stddev</th>\n",
       "      <th>onset_str_entropy</th>\n",
       "      <th>onset_time_diff_mean</th>\n",
       "      <th>onset_time_diff_stddev</th>\n",
       "      <th>onset_time_diff_entropy</th>\n",
       "      <th>word_rate</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>year</th>\n",
       "      <th>justice_word_count_mean</th>\n",
       "      <th>justice_word_count_std</th>\n",
       "      <th>justice_duration_mean</th>\n",
       "      <th>justice_duration_std</th>\n",
       "      <th>justice_gs_score_mean</th>\n",
       "      <th>justice_gs_score_std</th>\n",
       "      <th>justice_pitch_log_diff_variance_mean</th>\n",
       "      <th>justice_pitch_log_diff_variance_std</th>\n",
       "      <th>justice_pitch_log_mean_mean</th>\n",
       "      <th>justice_pitch_log_mean_std</th>\n",
       "      <th>justice_pitch_log_stdev_mean</th>\n",
       "      <th>justice_pitch_log_stdev_std</th>\n",
       "      <th>justice_pitch_log_2pct_mean</th>\n",
       "      <th>justice_pitch_log_2pct_std</th>\n",
       "      <th>justice_pitch_log_25pct_mean</th>\n",
       "      <th>justice_pitch_log_25pct_std</th>\n",
       "      <th>justice_pitch_log_50pct_mean</th>\n",
       "      <th>justice_pitch_log_50pct_std</th>\n",
       "      <th>justice_pitch_log_75pct_mean</th>\n",
       "      <th>justice_pitch_log_75pct_std</th>\n",
       "      <th>justice_pitch_log_98pct_mean</th>\n",
       "      <th>justice_pitch_log_98pct_std</th>\n",
       "      <th>justice_onset_count_mean</th>\n",
       "      <th>justice_onset_count_std</th>\n",
       "      <th>justice_onset_str_mean_mean</th>\n",
       "      <th>justice_onset_str_mean_std</th>\n",
       "      <th>justice_onset_str_stddev_mean</th>\n",
       "      <th>justice_onset_str_stddev_std</th>\n",
       "      <th>justice_onset_str_entropy_mean</th>\n",
       "      <th>justice_onset_str_entropy_std</th>\n",
       "      <th>justice_onset_time_diff_mean_mean</th>\n",
       "      <th>justice_onset_time_diff_mean_std</th>\n",
       "      <th>justice_onset_time_diff_stddev_mean</th>\n",
       "      <th>justice_onset_time_diff_stddev_std</th>\n",
       "      <th>justice_onset_time_diff_entropy_mean</th>\n",
       "      <th>justice_onset_time_diff_entropy_std</th>\n",
       "      <th>justice_word_rate_mean</th>\n",
       "      <th>justice_word_rate_std</th>\n",
       "      <th>justice_onset_rate_mean</th>\n",
       "      <th>justice_onset_rate_std</th>\n",
       "      <th>justice_year_word_count_mean</th>\n",
       "      <th>justice_year_word_count_std</th>\n",
       "      <th>justice_year_duration_mean</th>\n",
       "      <th>justice_year_duration_std</th>\n",
       "      <th>justice_year_gs_score_mean</th>\n",
       "      <th>justice_year_gs_score_std</th>\n",
       "      <th>justice_year_pitch_log_diff_variance_mean</th>\n",
       "      <th>justice_year_pitch_log_diff_variance_std</th>\n",
       "      <th>justice_year_pitch_log_mean_mean</th>\n",
       "      <th>justice_year_pitch_log_mean_std</th>\n",
       "      <th>justice_year_pitch_log_stdev_mean</th>\n",
       "      <th>justice_year_pitch_log_stdev_std</th>\n",
       "      <th>justice_year_pitch_log_2pct_mean</th>\n",
       "      <th>justice_year_pitch_log_2pct_std</th>\n",
       "      <th>justice_year_pitch_log_25pct_mean</th>\n",
       "      <th>justice_year_pitch_log_25pct_std</th>\n",
       "      <th>justice_year_pitch_log_50pct_mean</th>\n",
       "      <th>justice_year_pitch_log_50pct_std</th>\n",
       "      <th>justice_year_pitch_log_75pct_mean</th>\n",
       "      <th>justice_year_pitch_log_75pct_std</th>\n",
       "      <th>justice_year_pitch_log_98pct_mean</th>\n",
       "      <th>justice_year_pitch_log_98pct_std</th>\n",
       "      <th>justice_year_onset_count_mean</th>\n",
       "      <th>justice_year_onset_count_std</th>\n",
       "      <th>justice_year_onset_str_mean_mean</th>\n",
       "      <th>justice_year_onset_str_mean_std</th>\n",
       "      <th>justice_year_onset_str_stddev_mean</th>\n",
       "      <th>justice_year_onset_str_stddev_std</th>\n",
       "      <th>justice_year_onset_str_entropy_mean</th>\n",
       "      <th>justice_year_onset_str_entropy_std</th>\n",
       "      <th>justice_year_onset_time_diff_mean_mean</th>\n",
       "      <th>justice_year_onset_time_diff_mean_std</th>\n",
       "      <th>justice_year_onset_time_diff_stddev_mean</th>\n",
       "      <th>justice_year_onset_time_diff_stddev_std</th>\n",
       "      <th>justice_year_onset_time_diff_entropy_mean</th>\n",
       "      <th>justice_year_onset_time_diff_entropy_std</th>\n",
       "      <th>justice_year_word_rate_mean</th>\n",
       "      <th>justice_year_word_rate_std</th>\n",
       "      <th>justice_year_onset_rate_mean</th>\n",
       "      <th>justice_year_onset_rate_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-681</td>\n",
       "      <td>4</td>\n",
       "      <td>62.906</td>\n",
       "      <td>82.218</td>\n",
       "      <td>Ruth_Bader_Ginsburg</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>45</td>\n",
       "      <td>19.312</td>\n",
       "      <td>But how does it differ from the typical bargai...</td>\n",
       "      <td>1006496</td>\n",
       "      <td>1315488</td>\n",
       "      <td>-1.173626</td>\n",
       "      <td>4.420750</td>\n",
       "      <td>5.279096</td>\n",
       "      <td>3.690280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.710526</td>\n",
       "      <td>7.864693</td>\n",
       "      <td>8.272526</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.784787</td>\n",
       "      <td>1.376932</td>\n",
       "      <td>-3.093341</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>0.214818</td>\n",
       "      <td>-79.000485</td>\n",
       "      <td>2.330157</td>\n",
       "      <td>6.006628</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>65.111683</td>\n",
       "      <td>23.936758</td>\n",
       "      <td>30.546159</td>\n",
       "      <td>12.900663</td>\n",
       "      <td>-0.120233</td>\n",
       "      <td>0.619828</td>\n",
       "      <td>4.332276</td>\n",
       "      <td>0.771608</td>\n",
       "      <td>4.374778</td>\n",
       "      <td>0.845197</td>\n",
       "      <td>3.732496</td>\n",
       "      <td>0.182046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204550</td>\n",
       "      <td>1.208909</td>\n",
       "      <td>5.598532</td>\n",
       "      <td>3.247815</td>\n",
       "      <td>7.666009</td>\n",
       "      <td>0.706801</td>\n",
       "      <td>8.215027</td>\n",
       "      <td>0.137034</td>\n",
       "      <td>171.511389</td>\n",
       "      <td>61.861765</td>\n",
       "      <td>0.682518</td>\n",
       "      <td>0.075204</td>\n",
       "      <td>1.139276</td>\n",
       "      <td>0.156244</td>\n",
       "      <td>-3.898827</td>\n",
       "      <td>1.008391</td>\n",
       "      <td>0.238596</td>\n",
       "      <td>0.049807</td>\n",
       "      <td>0.256829</td>\n",
       "      <td>0.069155</td>\n",
       "      <td>-63.762414</td>\n",
       "      <td>36.458768</td>\n",
       "      <td>2.200660</td>\n",
       "      <td>0.373876</td>\n",
       "      <td>5.771207</td>\n",
       "      <td>0.902757</td>\n",
       "      <td>68.093496</td>\n",
       "      <td>23.457547</td>\n",
       "      <td>32.766317</td>\n",
       "      <td>12.892902</td>\n",
       "      <td>-0.195107</td>\n",
       "      <td>0.624182</td>\n",
       "      <td>4.312981</td>\n",
       "      <td>0.726183</td>\n",
       "      <td>4.787263</td>\n",
       "      <td>0.597654</td>\n",
       "      <td>3.698301</td>\n",
       "      <td>0.180863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301190</td>\n",
       "      <td>1.466223</td>\n",
       "      <td>7.070379</td>\n",
       "      <td>1.639869</td>\n",
       "      <td>7.784569</td>\n",
       "      <td>0.138150</td>\n",
       "      <td>8.266880</td>\n",
       "      <td>0.125538</td>\n",
       "      <td>186.662602</td>\n",
       "      <td>66.358980</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.065423</td>\n",
       "      <td>1.160205</td>\n",
       "      <td>0.122135</td>\n",
       "      <td>-3.589175</td>\n",
       "      <td>0.825202</td>\n",
       "      <td>0.238431</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.251816</td>\n",
       "      <td>0.063445</td>\n",
       "      <td>-62.786753</td>\n",
       "      <td>38.406475</td>\n",
       "      <td>2.141787</td>\n",
       "      <td>0.350414</td>\n",
       "      <td>5.837687</td>\n",
       "      <td>0.860461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-681</td>\n",
       "      <td>6</td>\n",
       "      <td>99.497</td>\n",
       "      <td>119.410</td>\n",
       "      <td>Sonia_Sotomayor</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>40</td>\n",
       "      <td>19.913</td>\n",
       "      <td>Is your argument dependent on this being sort ...</td>\n",
       "      <td>1591952</td>\n",
       "      <td>1910560</td>\n",
       "      <td>-0.831369</td>\n",
       "      <td>5.219659</td>\n",
       "      <td>5.901629</td>\n",
       "      <td>3.254473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.448026</td>\n",
       "      <td>7.598026</td>\n",
       "      <td>7.714693</td>\n",
       "      <td>8.227693</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.836102</td>\n",
       "      <td>1.251647</td>\n",
       "      <td>-2.760410</td>\n",
       "      <td>0.199184</td>\n",
       "      <td>0.188514</td>\n",
       "      <td>-80.602775</td>\n",
       "      <td>2.008738</td>\n",
       "      <td>6.729272</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>77.334467</td>\n",
       "      <td>41.758476</td>\n",
       "      <td>34.769708</td>\n",
       "      <td>20.796825</td>\n",
       "      <td>0.092309</td>\n",
       "      <td>0.637809</td>\n",
       "      <td>4.706124</td>\n",
       "      <td>0.856049</td>\n",
       "      <td>4.161151</td>\n",
       "      <td>0.699951</td>\n",
       "      <td>3.848770</td>\n",
       "      <td>0.133221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>0.546266</td>\n",
       "      <td>5.032356</td>\n",
       "      <td>3.538253</td>\n",
       "      <td>7.773903</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>8.356030</td>\n",
       "      <td>0.157197</td>\n",
       "      <td>191.458139</td>\n",
       "      <td>97.296963</td>\n",
       "      <td>0.790240</td>\n",
       "      <td>0.085811</td>\n",
       "      <td>1.320162</td>\n",
       "      <td>0.276336</td>\n",
       "      <td>-3.139069</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>0.239197</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>0.244760</td>\n",
       "      <td>0.080329</td>\n",
       "      <td>-66.041147</td>\n",
       "      <td>35.301185</td>\n",
       "      <td>2.309561</td>\n",
       "      <td>0.366808</td>\n",
       "      <td>5.798535</td>\n",
       "      <td>1.165566</td>\n",
       "      <td>67.966942</td>\n",
       "      <td>33.664795</td>\n",
       "      <td>29.056905</td>\n",
       "      <td>16.303318</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.623982</td>\n",
       "      <td>4.773675</td>\n",
       "      <td>0.811224</td>\n",
       "      <td>4.452683</td>\n",
       "      <td>0.664644</td>\n",
       "      <td>3.783437</td>\n",
       "      <td>0.137565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087811</td>\n",
       "      <td>0.787919</td>\n",
       "      <td>6.107304</td>\n",
       "      <td>2.898348</td>\n",
       "      <td>7.763712</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>8.324214</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>178.694215</td>\n",
       "      <td>86.327067</td>\n",
       "      <td>0.811963</td>\n",
       "      <td>0.056407</td>\n",
       "      <td>1.251543</td>\n",
       "      <td>0.121720</td>\n",
       "      <td>-3.276122</td>\n",
       "      <td>0.870668</td>\n",
       "      <td>0.204729</td>\n",
       "      <td>0.037861</td>\n",
       "      <td>0.206904</td>\n",
       "      <td>0.050275</td>\n",
       "      <td>-83.509931</td>\n",
       "      <td>46.029953</td>\n",
       "      <td>2.434882</td>\n",
       "      <td>0.391229</td>\n",
       "      <td>6.390440</td>\n",
       "      <td>0.945190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-681</td>\n",
       "      <td>16</td>\n",
       "      <td>201.764</td>\n",
       "      <td>227.298</td>\n",
       "      <td>Antonin_Scalia</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>68</td>\n",
       "      <td>25.534</td>\n",
       "      <td>Suppose you have a policeman who -- who is dis...</td>\n",
       "      <td>3228224</td>\n",
       "      <td>3636768</td>\n",
       "      <td>0.740117</td>\n",
       "      <td>2.205882</td>\n",
       "      <td>1.510731</td>\n",
       "      <td>3.044242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.190193</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.828926</td>\n",
       "      <td>1.236061</td>\n",
       "      <td>-3.053182</td>\n",
       "      <td>0.194540</td>\n",
       "      <td>0.171645</td>\n",
       "      <td>-107.241318</td>\n",
       "      <td>2.663116</td>\n",
       "      <td>6.853607</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>70.334333</td>\n",
       "      <td>31.825077</td>\n",
       "      <td>26.995090</td>\n",
       "      <td>14.396301</td>\n",
       "      <td>0.338013</td>\n",
       "      <td>0.625946</td>\n",
       "      <td>3.342199</td>\n",
       "      <td>1.172944</td>\n",
       "      <td>2.627005</td>\n",
       "      <td>0.973397</td>\n",
       "      <td>3.455633</td>\n",
       "      <td>0.424548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.290970</td>\n",
       "      <td>0.848407</td>\n",
       "      <td>2.335051</td>\n",
       "      <td>5.735460</td>\n",
       "      <td>3.081819</td>\n",
       "      <td>8.138378</td>\n",
       "      <td>0.323390</td>\n",
       "      <td>178.032984</td>\n",
       "      <td>85.316645</td>\n",
       "      <td>0.844748</td>\n",
       "      <td>0.075775</td>\n",
       "      <td>1.228364</td>\n",
       "      <td>0.128015</td>\n",
       "      <td>-3.127796</td>\n",
       "      <td>0.789180</td>\n",
       "      <td>0.194310</td>\n",
       "      <td>0.036077</td>\n",
       "      <td>0.185192</td>\n",
       "      <td>0.046597</td>\n",
       "      <td>-100.014029</td>\n",
       "      <td>54.261628</td>\n",
       "      <td>2.720814</td>\n",
       "      <td>0.460809</td>\n",
       "      <td>6.776469</td>\n",
       "      <td>0.925876</td>\n",
       "      <td>72.217666</td>\n",
       "      <td>33.705443</td>\n",
       "      <td>27.522858</td>\n",
       "      <td>15.549641</td>\n",
       "      <td>0.366035</td>\n",
       "      <td>0.649845</td>\n",
       "      <td>3.094893</td>\n",
       "      <td>1.119518</td>\n",
       "      <td>2.405132</td>\n",
       "      <td>0.897115</td>\n",
       "      <td>3.372408</td>\n",
       "      <td>0.443051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429890</td>\n",
       "      <td>1.706210</td>\n",
       "      <td>5.281057</td>\n",
       "      <td>3.272145</td>\n",
       "      <td>8.082980</td>\n",
       "      <td>0.360789</td>\n",
       "      <td>180.182965</td>\n",
       "      <td>90.189031</td>\n",
       "      <td>0.844991</td>\n",
       "      <td>0.074487</td>\n",
       "      <td>1.230093</td>\n",
       "      <td>0.125249</td>\n",
       "      <td>-3.054152</td>\n",
       "      <td>0.783185</td>\n",
       "      <td>0.197227</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>0.185871</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>-99.108423</td>\n",
       "      <td>53.589374</td>\n",
       "      <td>2.756272</td>\n",
       "      <td>0.472502</td>\n",
       "      <td>6.747949</td>\n",
       "      <td>0.930417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-681</td>\n",
       "      <td>22</td>\n",
       "      <td>273.827</td>\n",
       "      <td>286.853</td>\n",
       "      <td>Antonin_Scalia</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>50</td>\n",
       "      <td>13.026</td>\n",
       "      <td>It seems to me it's always a matter of public ...</td>\n",
       "      <td>4381232</td>\n",
       "      <td>4589648</td>\n",
       "      <td>0.326807</td>\n",
       "      <td>5.557836</td>\n",
       "      <td>3.639624</td>\n",
       "      <td>3.912106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.670943</td>\n",
       "      <td>8.485026</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>1.213430</td>\n",
       "      <td>-3.421826</td>\n",
       "      <td>0.169813</td>\n",
       "      <td>0.159185</td>\n",
       "      <td>-93.589232</td>\n",
       "      <td>3.838477</td>\n",
       "      <td>7.600184</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>70.334333</td>\n",
       "      <td>31.825077</td>\n",
       "      <td>26.995090</td>\n",
       "      <td>14.396301</td>\n",
       "      <td>0.338013</td>\n",
       "      <td>0.625946</td>\n",
       "      <td>3.342199</td>\n",
       "      <td>1.172944</td>\n",
       "      <td>2.627005</td>\n",
       "      <td>0.973397</td>\n",
       "      <td>3.455633</td>\n",
       "      <td>0.424548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.290970</td>\n",
       "      <td>0.848407</td>\n",
       "      <td>2.335051</td>\n",
       "      <td>5.735460</td>\n",
       "      <td>3.081819</td>\n",
       "      <td>8.138378</td>\n",
       "      <td>0.323390</td>\n",
       "      <td>178.032984</td>\n",
       "      <td>85.316645</td>\n",
       "      <td>0.844748</td>\n",
       "      <td>0.075775</td>\n",
       "      <td>1.228364</td>\n",
       "      <td>0.128015</td>\n",
       "      <td>-3.127796</td>\n",
       "      <td>0.789180</td>\n",
       "      <td>0.194310</td>\n",
       "      <td>0.036077</td>\n",
       "      <td>0.185192</td>\n",
       "      <td>0.046597</td>\n",
       "      <td>-100.014029</td>\n",
       "      <td>54.261628</td>\n",
       "      <td>2.720814</td>\n",
       "      <td>0.460809</td>\n",
       "      <td>6.776469</td>\n",
       "      <td>0.925876</td>\n",
       "      <td>72.217666</td>\n",
       "      <td>33.705443</td>\n",
       "      <td>27.522858</td>\n",
       "      <td>15.549641</td>\n",
       "      <td>0.366035</td>\n",
       "      <td>0.649845</td>\n",
       "      <td>3.094893</td>\n",
       "      <td>1.119518</td>\n",
       "      <td>2.405132</td>\n",
       "      <td>0.897115</td>\n",
       "      <td>3.372408</td>\n",
       "      <td>0.443051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429890</td>\n",
       "      <td>1.706210</td>\n",
       "      <td>5.281057</td>\n",
       "      <td>3.272145</td>\n",
       "      <td>8.082980</td>\n",
       "      <td>0.360789</td>\n",
       "      <td>180.182965</td>\n",
       "      <td>90.189031</td>\n",
       "      <td>0.844991</td>\n",
       "      <td>0.074487</td>\n",
       "      <td>1.230093</td>\n",
       "      <td>0.125249</td>\n",
       "      <td>-3.054152</td>\n",
       "      <td>0.783185</td>\n",
       "      <td>0.197227</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>0.185871</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>-99.108423</td>\n",
       "      <td>53.589374</td>\n",
       "      <td>2.756272</td>\n",
       "      <td>0.472502</td>\n",
       "      <td>6.747949</td>\n",
       "      <td>0.930417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-681</td>\n",
       "      <td>32</td>\n",
       "      <td>350.343</td>\n",
       "      <td>397.472</td>\n",
       "      <td>Elena_Kagan</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>130</td>\n",
       "      <td>47.129</td>\n",
       "      <td>But what -- what you're objecting to, to the e...</td>\n",
       "      <td>5605488</td>\n",
       "      <td>6359552</td>\n",
       "      <td>0.494308</td>\n",
       "      <td>6.028679</td>\n",
       "      <td>5.517903</td>\n",
       "      <td>3.566414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.581360</td>\n",
       "      <td>7.873026</td>\n",
       "      <td>8.598026</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.952412</td>\n",
       "      <td>1.375316</td>\n",
       "      <td>-2.769539</td>\n",
       "      <td>0.174394</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>-116.278131</td>\n",
       "      <td>2.758387</td>\n",
       "      <td>7.193023</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>85.640900</td>\n",
       "      <td>39.861284</td>\n",
       "      <td>30.113618</td>\n",
       "      <td>15.031800</td>\n",
       "      <td>0.148144</td>\n",
       "      <td>0.630669</td>\n",
       "      <td>5.672490</td>\n",
       "      <td>0.974220</td>\n",
       "      <td>4.805985</td>\n",
       "      <td>0.745291</td>\n",
       "      <td>3.714562</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422594</td>\n",
       "      <td>1.706773</td>\n",
       "      <td>6.811690</td>\n",
       "      <td>2.217334</td>\n",
       "      <td>7.749512</td>\n",
       "      <td>0.563223</td>\n",
       "      <td>8.473073</td>\n",
       "      <td>0.172455</td>\n",
       "      <td>193.155306</td>\n",
       "      <td>91.744927</td>\n",
       "      <td>0.940246</td>\n",
       "      <td>0.106289</td>\n",
       "      <td>1.430348</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>-2.451043</td>\n",
       "      <td>0.686988</td>\n",
       "      <td>0.212165</td>\n",
       "      <td>0.081194</td>\n",
       "      <td>0.181419</td>\n",
       "      <td>0.074681</td>\n",
       "      <td>-115.162629</td>\n",
       "      <td>59.032724</td>\n",
       "      <td>2.909919</td>\n",
       "      <td>0.372382</td>\n",
       "      <td>6.586837</td>\n",
       "      <td>1.188517</td>\n",
       "      <td>82.337838</td>\n",
       "      <td>37.349545</td>\n",
       "      <td>28.245946</td>\n",
       "      <td>13.753225</td>\n",
       "      <td>0.081279</td>\n",
       "      <td>0.672290</td>\n",
       "      <td>5.733289</td>\n",
       "      <td>0.813327</td>\n",
       "      <td>5.362105</td>\n",
       "      <td>0.564749</td>\n",
       "      <td>3.569872</td>\n",
       "      <td>0.213117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.389261</td>\n",
       "      <td>2.882529</td>\n",
       "      <td>7.508138</td>\n",
       "      <td>0.793901</td>\n",
       "      <td>7.827880</td>\n",
       "      <td>0.139891</td>\n",
       "      <td>8.495513</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>199.797297</td>\n",
       "      <td>89.338366</td>\n",
       "      <td>0.902198</td>\n",
       "      <td>0.053643</td>\n",
       "      <td>1.267149</td>\n",
       "      <td>0.109391</td>\n",
       "      <td>-2.890523</td>\n",
       "      <td>0.661673</td>\n",
       "      <td>0.178505</td>\n",
       "      <td>0.027986</td>\n",
       "      <td>0.151338</td>\n",
       "      <td>0.030079</td>\n",
       "      <td>-136.943023</td>\n",
       "      <td>56.329519</td>\n",
       "      <td>2.982173</td>\n",
       "      <td>0.376701</td>\n",
       "      <td>7.209296</td>\n",
       "      <td>0.770327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file  line    start      end              speaker    speaker_role  \\\n",
       "0  11-681     4   62.906   82.218  Ruth_Bader_Ginsburg  scotus_justice   \n",
       "1  11-681     6   99.497  119.410      Sonia_Sotomayor  scotus_justice   \n",
       "2  11-681    16  201.764  227.298       Antonin_Scalia  scotus_justice   \n",
       "3  11-681    22  273.827  286.853       Antonin_Scalia  scotus_justice   \n",
       "4  11-681    32  350.343  397.472          Elena_Kagan  scotus_justice   \n",
       "\n",
       "   word_count  duration                                               text  \\\n",
       "0          45    19.312  But how does it differ from the typical bargai...   \n",
       "1          40    19.913  Is your argument dependent on this being sort ...   \n",
       "2          68    25.534  Suppose you have a policeman who -- who is dis...   \n",
       "3          50    13.026  It seems to me it's always a matter of public ...   \n",
       "4         130    47.129  But what -- what you're objecting to, to the e...   \n",
       "\n",
       "   start_idx  end_idx  gs_score  pitch_log_diff_variance  pitch_log_mean  \\\n",
       "0    1006496  1315488 -1.173626                 4.420750        5.279096   \n",
       "1    1591952  1910560 -0.831369                 5.219659        5.901629   \n",
       "2    3228224  3636768  0.740117                 2.205882        1.510731   \n",
       "3    4381232  4589648  0.326807                 5.557836        3.639624   \n",
       "4    5605488  6359552  0.494308                 6.028679        5.517903   \n",
       "\n",
       "   pitch_log_stdev  pitch_log_2pct  pitch_log_25pct  pitch_log_50pct  \\\n",
       "0         3.690280             0.0         0.000000         7.710526   \n",
       "1         3.254473             0.0         7.448026         7.598026   \n",
       "2         3.044242             0.0         0.000000         0.000000   \n",
       "3         3.912106             0.0         0.000000         0.000000   \n",
       "4         3.566414             0.0         0.000000         7.581360   \n",
       "\n",
       "   pitch_log_75pct  pitch_log_98pct  onset_count  onset_str_mean  \\\n",
       "0         7.864693         8.272526        116.0        0.784787   \n",
       "1         7.714693         8.227693        134.0        0.836102   \n",
       "2         0.000000         8.190193        175.0        0.828926   \n",
       "3         7.670943         8.485026         99.0        0.872724   \n",
       "4         7.873026         8.598026        339.0        0.952412   \n",
       "\n",
       "   onset_str_stddev  onset_str_entropy  onset_time_diff_mean  \\\n",
       "0          1.376932          -3.093341              0.227200   \n",
       "1          1.251647          -2.760410              0.199184   \n",
       "2          1.236061          -3.053182              0.194540   \n",
       "3          1.213430          -3.421826              0.169813   \n",
       "4          1.375316          -2.769539              0.174394   \n",
       "\n",
       "   onset_time_diff_stddev  onset_time_diff_entropy  word_rate  onset_rate  \\\n",
       "0                0.214818               -79.000485   2.330157    6.006628   \n",
       "1                0.188514               -80.602775   2.008738    6.729272   \n",
       "2                0.171645              -107.241318   2.663116    6.853607   \n",
       "3                0.159185               -93.589232   3.838477    7.600184   \n",
       "4                0.147465              -116.278131   2.758387    7.193023   \n",
       "\n",
       "     year  justice_word_count_mean  justice_word_count_std  \\\n",
       "0  2013.0                65.111683               23.936758   \n",
       "1  2013.0                77.334467               41.758476   \n",
       "2  2013.0                70.334333               31.825077   \n",
       "3  2013.0                70.334333               31.825077   \n",
       "4  2013.0                85.640900               39.861284   \n",
       "\n",
       "   justice_duration_mean  justice_duration_std  justice_gs_score_mean  \\\n",
       "0              30.546159             12.900663              -0.120233   \n",
       "1              34.769708             20.796825               0.092309   \n",
       "2              26.995090             14.396301               0.338013   \n",
       "3              26.995090             14.396301               0.338013   \n",
       "4              30.113618             15.031800               0.148144   \n",
       "\n",
       "   justice_gs_score_std  justice_pitch_log_diff_variance_mean  \\\n",
       "0              0.619828                              4.332276   \n",
       "1              0.637809                              4.706124   \n",
       "2              0.625946                              3.342199   \n",
       "3              0.625946                              3.342199   \n",
       "4              0.630669                              5.672490   \n",
       "\n",
       "   justice_pitch_log_diff_variance_std  justice_pitch_log_mean_mean  \\\n",
       "0                             0.771608                     4.374778   \n",
       "1                             0.856049                     4.161151   \n",
       "2                             1.172944                     2.627005   \n",
       "3                             1.172944                     2.627005   \n",
       "4                             0.974220                     4.805985   \n",
       "\n",
       "   justice_pitch_log_mean_std  justice_pitch_log_stdev_mean  \\\n",
       "0                    0.845197                      3.732496   \n",
       "1                    0.699951                      3.848770   \n",
       "2                    0.973397                      3.455633   \n",
       "3                    0.973397                      3.455633   \n",
       "4                    0.745291                      3.714562   \n",
       "\n",
       "   justice_pitch_log_stdev_std  justice_pitch_log_2pct_mean  \\\n",
       "0                     0.182046                          0.0   \n",
       "1                     0.133221                          0.0   \n",
       "2                     0.424548                          0.0   \n",
       "3                     0.424548                          0.0   \n",
       "4                     0.196628                          0.0   \n",
       "\n",
       "   justice_pitch_log_2pct_std  justice_pitch_log_25pct_mean  \\\n",
       "0                         0.0                      0.204550   \n",
       "1                         0.0                      0.040663   \n",
       "2                         0.0                      0.011266   \n",
       "3                         0.0                      0.011266   \n",
       "4                         0.0                      0.422594   \n",
       "\n",
       "   justice_pitch_log_25pct_std  justice_pitch_log_50pct_mean  \\\n",
       "0                     1.208909                      5.598532   \n",
       "1                     0.546266                      5.032356   \n",
       "2                     0.290970                      0.848407   \n",
       "3                     0.290970                      0.848407   \n",
       "4                     1.706773                      6.811690   \n",
       "\n",
       "   justice_pitch_log_50pct_std  justice_pitch_log_75pct_mean  \\\n",
       "0                     3.247815                      7.666009   \n",
       "1                     3.538253                      7.773903   \n",
       "2                     2.335051                      5.735460   \n",
       "3                     2.335051                      5.735460   \n",
       "4                     2.217334                      7.749512   \n",
       "\n",
       "   justice_pitch_log_75pct_std  justice_pitch_log_98pct_mean  \\\n",
       "0                     0.706801                      8.215027   \n",
       "1                     0.593608                      8.356030   \n",
       "2                     3.081819                      8.138378   \n",
       "3                     3.081819                      8.138378   \n",
       "4                     0.563223                      8.473073   \n",
       "\n",
       "   justice_pitch_log_98pct_std  justice_onset_count_mean  \\\n",
       "0                     0.137034                171.511389   \n",
       "1                     0.157197                191.458139   \n",
       "2                     0.323390                178.032984   \n",
       "3                     0.323390                178.032984   \n",
       "4                     0.172455                193.155306   \n",
       "\n",
       "   justice_onset_count_std  justice_onset_str_mean_mean  \\\n",
       "0                61.861765                     0.682518   \n",
       "1                97.296963                     0.790240   \n",
       "2                85.316645                     0.844748   \n",
       "3                85.316645                     0.844748   \n",
       "4                91.744927                     0.940246   \n",
       "\n",
       "   justice_onset_str_mean_std  justice_onset_str_stddev_mean  \\\n",
       "0                    0.075204                       1.139276   \n",
       "1                    0.085811                       1.320162   \n",
       "2                    0.075775                       1.228364   \n",
       "3                    0.075775                       1.228364   \n",
       "4                    0.106289                       1.430348   \n",
       "\n",
       "   justice_onset_str_stddev_std  justice_onset_str_entropy_mean  \\\n",
       "0                      0.156244                       -3.898827   \n",
       "1                      0.276336                       -3.139069   \n",
       "2                      0.128015                       -3.127796   \n",
       "3                      0.128015                       -3.127796   \n",
       "4                      0.206924                       -2.451043   \n",
       "\n",
       "   justice_onset_str_entropy_std  justice_onset_time_diff_mean_mean  \\\n",
       "0                       1.008391                           0.238596   \n",
       "1                       0.996656                           0.239197   \n",
       "2                       0.789180                           0.194310   \n",
       "3                       0.789180                           0.194310   \n",
       "4                       0.686988                           0.212165   \n",
       "\n",
       "   justice_onset_time_diff_mean_std  justice_onset_time_diff_stddev_mean  \\\n",
       "0                          0.049807                             0.256829   \n",
       "1                          0.081724                             0.244760   \n",
       "2                          0.036077                             0.185192   \n",
       "3                          0.036077                             0.185192   \n",
       "4                          0.081194                             0.181419   \n",
       "\n",
       "   justice_onset_time_diff_stddev_std  justice_onset_time_diff_entropy_mean  \\\n",
       "0                            0.069155                            -63.762414   \n",
       "1                            0.080329                            -66.041147   \n",
       "2                            0.046597                           -100.014029   \n",
       "3                            0.046597                           -100.014029   \n",
       "4                            0.074681                           -115.162629   \n",
       "\n",
       "   justice_onset_time_diff_entropy_std  justice_word_rate_mean  \\\n",
       "0                            36.458768                2.200660   \n",
       "1                            35.301185                2.309561   \n",
       "2                            54.261628                2.720814   \n",
       "3                            54.261628                2.720814   \n",
       "4                            59.032724                2.909919   \n",
       "\n",
       "   justice_word_rate_std  justice_onset_rate_mean  justice_onset_rate_std  \\\n",
       "0               0.373876                 5.771207                0.902757   \n",
       "1               0.366808                 5.798535                1.165566   \n",
       "2               0.460809                 6.776469                0.925876   \n",
       "3               0.460809                 6.776469                0.925876   \n",
       "4               0.372382                 6.586837                1.188517   \n",
       "\n",
       "   justice_year_word_count_mean  justice_year_word_count_std  \\\n",
       "0                     68.093496                    23.457547   \n",
       "1                     67.966942                    33.664795   \n",
       "2                     72.217666                    33.705443   \n",
       "3                     72.217666                    33.705443   \n",
       "4                     82.337838                    37.349545   \n",
       "\n",
       "   justice_year_duration_mean  justice_year_duration_std  \\\n",
       "0                   32.766317                  12.892902   \n",
       "1                   29.056905                  16.303318   \n",
       "2                   27.522858                  15.549641   \n",
       "3                   27.522858                  15.549641   \n",
       "4                   28.245946                  13.753225   \n",
       "\n",
       "   justice_year_gs_score_mean  justice_year_gs_score_std  \\\n",
       "0                   -0.195107                   0.624182   \n",
       "1                    0.003989                   0.623982   \n",
       "2                    0.366035                   0.649845   \n",
       "3                    0.366035                   0.649845   \n",
       "4                    0.081279                   0.672290   \n",
       "\n",
       "   justice_year_pitch_log_diff_variance_mean  \\\n",
       "0                                   4.312981   \n",
       "1                                   4.773675   \n",
       "2                                   3.094893   \n",
       "3                                   3.094893   \n",
       "4                                   5.733289   \n",
       "\n",
       "   justice_year_pitch_log_diff_variance_std  justice_year_pitch_log_mean_mean  \\\n",
       "0                                  0.726183                          4.787263   \n",
       "1                                  0.811224                          4.452683   \n",
       "2                                  1.119518                          2.405132   \n",
       "3                                  1.119518                          2.405132   \n",
       "4                                  0.813327                          5.362105   \n",
       "\n",
       "   justice_year_pitch_log_mean_std  justice_year_pitch_log_stdev_mean  \\\n",
       "0                         0.597654                           3.698301   \n",
       "1                         0.664644                           3.783437   \n",
       "2                         0.897115                           3.372408   \n",
       "3                         0.897115                           3.372408   \n",
       "4                         0.564749                           3.569872   \n",
       "\n",
       "   justice_year_pitch_log_stdev_std  justice_year_pitch_log_2pct_mean  \\\n",
       "0                          0.180863                               0.0   \n",
       "1                          0.137565                               0.0   \n",
       "2                          0.443051                               0.0   \n",
       "3                          0.443051                               0.0   \n",
       "4                          0.213117                               0.0   \n",
       "\n",
       "   justice_year_pitch_log_2pct_std  justice_year_pitch_log_25pct_mean  \\\n",
       "0                              0.0                           0.301190   \n",
       "1                              0.0                           0.087811   \n",
       "2                              0.0                           0.000000   \n",
       "3                              0.0                           0.000000   \n",
       "4                              0.0                           1.389261   \n",
       "\n",
       "   justice_year_pitch_log_25pct_std  justice_year_pitch_log_50pct_mean  \\\n",
       "0                          1.466223                           7.070379   \n",
       "1                          0.787919                           6.107304   \n",
       "2                          0.000000                           0.429890   \n",
       "3                          0.000000                           0.429890   \n",
       "4                          2.882529                           7.508138   \n",
       "\n",
       "   justice_year_pitch_log_50pct_std  justice_year_pitch_log_75pct_mean  \\\n",
       "0                          1.639869                           7.784569   \n",
       "1                          2.898348                           7.763712   \n",
       "2                          1.706210                           5.281057   \n",
       "3                          1.706210                           5.281057   \n",
       "4                          0.793901                           7.827880   \n",
       "\n",
       "   justice_year_pitch_log_75pct_std  justice_year_pitch_log_98pct_mean  \\\n",
       "0                          0.138150                           8.266880   \n",
       "1                          0.128137                           8.324214   \n",
       "2                          3.272145                           8.082980   \n",
       "3                          3.272145                           8.082980   \n",
       "4                          0.139891                           8.495513   \n",
       "\n",
       "   justice_year_pitch_log_98pct_std  justice_year_onset_count_mean  \\\n",
       "0                          0.125538                     186.662602   \n",
       "1                          0.173540                     178.694215   \n",
       "2                          0.360789                     180.182965   \n",
       "3                          0.360789                     180.182965   \n",
       "4                          0.164981                     199.797297   \n",
       "\n",
       "   justice_year_onset_count_std  justice_year_onset_str_mean_mean  \\\n",
       "0                     66.358980                          0.701429   \n",
       "1                     86.327067                          0.811963   \n",
       "2                     90.189031                          0.844991   \n",
       "3                     90.189031                          0.844991   \n",
       "4                     89.338366                          0.902198   \n",
       "\n",
       "   justice_year_onset_str_mean_std  justice_year_onset_str_stddev_mean  \\\n",
       "0                         0.065423                            1.160205   \n",
       "1                         0.056407                            1.251543   \n",
       "2                         0.074487                            1.230093   \n",
       "3                         0.074487                            1.230093   \n",
       "4                         0.053643                            1.267149   \n",
       "\n",
       "   justice_year_onset_str_stddev_std  justice_year_onset_str_entropy_mean  \\\n",
       "0                           0.122135                            -3.589175   \n",
       "1                           0.121720                            -3.276122   \n",
       "2                           0.125249                            -3.054152   \n",
       "3                           0.125249                            -3.054152   \n",
       "4                           0.109391                            -2.890523   \n",
       "\n",
       "   justice_year_onset_str_entropy_std  justice_year_onset_time_diff_mean_mean  \\\n",
       "0                            0.825202                                0.238431   \n",
       "1                            0.870668                                0.204729   \n",
       "2                            0.783185                                0.197227   \n",
       "3                            0.783185                                0.197227   \n",
       "4                            0.661673                                0.178505   \n",
       "\n",
       "   justice_year_onset_time_diff_mean_std  \\\n",
       "0                               0.043301   \n",
       "1                               0.037861   \n",
       "2                               0.038226   \n",
       "3                               0.038226   \n",
       "4                               0.027986   \n",
       "\n",
       "   justice_year_onset_time_diff_stddev_mean  \\\n",
       "0                                  0.251816   \n",
       "1                                  0.206904   \n",
       "2                                  0.185871   \n",
       "3                                  0.185871   \n",
       "4                                  0.151338   \n",
       "\n",
       "   justice_year_onset_time_diff_stddev_std  \\\n",
       "0                                 0.063445   \n",
       "1                                 0.050275   \n",
       "2                                 0.047700   \n",
       "3                                 0.047700   \n",
       "4                                 0.030079   \n",
       "\n",
       "   justice_year_onset_time_diff_entropy_mean  \\\n",
       "0                                 -62.786753   \n",
       "1                                 -83.509931   \n",
       "2                                 -99.108423   \n",
       "3                                 -99.108423   \n",
       "4                                -136.943023   \n",
       "\n",
       "   justice_year_onset_time_diff_entropy_std  justice_year_word_rate_mean  \\\n",
       "0                                 38.406475                     2.141787   \n",
       "1                                 46.029953                     2.434882   \n",
       "2                                 53.589374                     2.756272   \n",
       "3                                 53.589374                     2.756272   \n",
       "4                                 56.329519                     2.982173   \n",
       "\n",
       "   justice_year_word_rate_std  justice_year_onset_rate_mean  \\\n",
       "0                    0.350414                      5.837687   \n",
       "1                    0.391229                      6.390440   \n",
       "2                    0.472502                      6.747949   \n",
       "3                    0.472502                      6.747949   \n",
       "4                    0.376701                      7.209296   \n",
       "\n",
       "   justice_year_onset_rate_std  \n",
       "0                     0.860461  \n",
       "1                     0.945190  \n",
       "2                     0.930417  \n",
       "3                     0.930417  \n",
       "4                     0.770327  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "every-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prerequisite-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file', 'line', 'start', 'end', 'speaker', 'speaker_role', 'word_count',\n",
       "       'duration', 'text', 'start_idx',\n",
       "       ...\n",
       "       'justice_year_onset_time_diff_mean_mean',\n",
       "       'justice_year_onset_time_diff_mean_std',\n",
       "       'justice_year_onset_time_diff_stddev_mean',\n",
       "       'justice_year_onset_time_diff_stddev_std',\n",
       "       'justice_year_onset_time_diff_entropy_mean',\n",
       "       'justice_year_onset_time_diff_entropy_std',\n",
       "       'justice_year_word_rate_mean', 'justice_year_word_rate_std',\n",
       "       'justice_year_onset_rate_mean', 'justice_year_onset_rate_std'],\n",
       "      dtype='object', length=110)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "drawn-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['file', 'line', 'start', 'end', 'speaker', 'speaker_role', 'text', \n",
    "         'start_idx','end_idx'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civic-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set half of score as grandstanding for now to keep balanced data\n",
    "\n",
    "df['Grandstanding_ind'] = np.where(df['gs_score']>data['gs_score'].mean(),1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "horizontal-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('gs_score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "circular-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "white-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Grandstanding_ind']\n",
    "y = df.loc[:, df.columns == 'Grandstanding_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "interim-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=117)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "returning-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "advised-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,  \n",
    "    test_size=0.2, random_state=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cross-event",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.629\n",
      "Accuracy score (validation): 0.621\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.625\n",
      "Accuracy score (validation): 0.620\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.626\n",
      "Accuracy score (validation): 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.639\n",
      "Accuracy score (validation): 0.628\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.675\n",
      "Accuracy score (validation): 0.658\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.687\n",
      "Accuracy score (validation): 0.658\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.680\n",
      "Accuracy score (validation): 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "attached-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  20\n",
      "Accuracy score (training): 0.687\n",
      "Accuracy score (validation): 0.658\n",
      "n_estimators:  50\n",
      "Accuracy score (training): 0.706\n",
      "Accuracy score (validation): 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  100\n",
      "Accuracy score (training): 0.727\n",
      "Accuracy score (validation): 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  200\n",
      "Accuracy score (training): 0.741\n",
      "Accuracy score (validation): 0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  500\n",
      "Accuracy score (training): 0.768\n",
      "Accuracy score (validation): 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  1000\n",
      "Accuracy score (training): 0.802\n",
      "Accuracy score (validation): 0.678\n"
     ]
    }
   ],
   "source": [
    "n = [20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "for i in n:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=i, learning_rate=0.75, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"n_estimators: \", i)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "proper-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features:  2\n",
      "Accuracy score (training): 0.741\n",
      "Accuracy score (validation): 0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features:  5\n",
      "Accuracy score (training): 0.758\n",
      "Accuracy score (validation): 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features:  10\n",
      "Accuracy score (training): 0.768\n",
      "Accuracy score (validation): 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features:  20\n",
      "Accuracy score (training): 0.778\n",
      "Accuracy score (validation): 0.671\n"
     ]
    }
   ],
   "source": [
    "max_fea = [2, 5, 10, 20]\n",
    "\n",
    "for i in max_fea:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.75, max_features=i, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"max_features: \", i)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "animal-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  2\n",
      "Accuracy score (training): 0.768\n",
      "Accuracy score (validation): 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  5\n",
      "Accuracy score (training): 0.991\n",
      "Accuracy score (validation): 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  10\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  20\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.599\n"
     ]
    }
   ],
   "source": [
    "max_dep = [2, 5, 10, 20]\n",
    "\n",
    "for i in max_dep:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.75, max_features=10, max_depth=i, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"max_depth: \", i)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "different-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 768  466]\n",
      " [ 441 1055]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      1234\n",
      "           1       0.69      0.71      0.70      1496\n",
      "\n",
      "    accuracy                           0.67      2730\n",
      "   macro avg       0.66      0.66      0.66      2730\n",
      "weighted avg       0.67      0.67      0.67      2730\n",
      "\n",
      "Confusion Matrix - test:\n",
      "[[1020  526]\n",
      " [ 543 1324]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      1546\n",
      "           1       0.72      0.71      0.71      1867\n",
      "\n",
      "    accuracy                           0.69      3413\n",
      "   macro avg       0.68      0.68      0.68      3413\n",
      "weighted avg       0.69      0.69      0.69      3413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_clf2 = GradientBoostingClassifier(n_estimators=200, learning_rate=0.75, max_features=10, max_depth=2, random_state=117)\n",
    "gb_clf2.fit(X_train, y_train)\n",
    "predictions = gb_clf2.predict(X_val)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, predictions))\n",
    "\n",
    "predictions2 = gb_clf2.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix - test:\")\n",
    "print(confusion_matrix(y_test, predictions2))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-barcelona",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
